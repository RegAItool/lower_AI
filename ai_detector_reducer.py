#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI Detection Reducer PRO - ç»ˆæç‰ˆ
ä½¿ç”¨è¶…æç«¯åŒé‡ç¿»è¯‘ + ä¸­å¼è‹±è¯­è¯­æ³•å¹²æ‰°

è¿™ä¸ªç‰ˆæœ¬åŒ…å«æ‰€æœ‰æœ€å¼ºçš„è½¬æ¢æŠ€æœ¯ï¼Œå¯ä»¥å°†AIæ£€æµ‹ç‡é™åˆ°æœ€ä½

ä½œè€…: Claude Code
ç‰ˆæœ¬: 3.0 PRO Ultimate
"""

import re
import sys
import os
from typing import Dict, List, Tuple
import argparse


class AIDetectorReducerPro:
    """AIæ£€æµ‹ç‡é™ä½å™¨ PROç‰ˆ - ç»ˆæåŒé‡ç¿»è¯‘å¼•æ“"""

    def __init__(self):
        """åˆå§‹åŒ–æ‰€æœ‰è½¬æ¢è§„åˆ™"""
        self.init_vocabulary_replacements()
        self.init_sentence_transformations()
        self.init_chinese_grammar_patterns()

    def init_vocabulary_replacements(self):
        """åˆå§‹åŒ–è¯æ±‡æ›¿æ¢è§„åˆ™"""
        # è¶…æç«¯åŠ¨è¯è½¬æ¢ï¼ˆç¬¬ä¸€ä¼˜å…ˆçº§ï¼‰
        self.verb_ultra_extreme = {
            r'\bdemonstrated\b': 'made coming to show',
            r'\bdemonstrates\b': 'makes coming to show',
            r'\bdemonstrate\b': 'make coming to show',
            r'\bindicated\b': 'gave pointing to',
            r'\bindicates\b': 'gives pointing to',
            r'\bindicate\b': 'give pointing to',
            r'\brevealed\b': 'let showing',
            r'\breveals\b': 'lets showing',
            r'\breveal\b': 'let show',
            r'\bparticipated\b': 'made taking part',
            r'\bparticipates\b': 'makes taking part',
            r'\bparticipate\b': 'make taking part',
            r'\bperformed\b': 'made doing',
            r'\bperforms\b': 'makes doing',
            r'\bperform\b': 'make doing',
            r'\bconducted\b': 'made happening',
            r'\bconducts\b': 'makes happening',
            r'\bconduct\b': 'make happening',
            r'\bidentified\b': 'came to spot',
            r'\bidentifies\b': 'comes to spot',
            r'\bidentify\b': 'come to spot',
            r'\bobserved\b': 'came to see',
            r'\bobserves\b': 'comes to see',
            r'\bobserve\b': 'come to see',
            r'\bcollected\b': 'brought together',
            r'\bcollects\b': 'brings together',
            r'\bcollect\b': 'bring together',
            r'\banalyzed\b': 'made looking at',
            r'\banalyzes\b': 'makes looking at',
            r'\banalyze\b': 'make looking at',
            r'\bemployed\b': 'put to use',
            r'\bemploys\b': 'puts to use',
            r'\bemploy\b': 'put to use',
            r'\bimplemented\b': 'made putting into practice',
            r'\bimplements\b': 'makes putting into practice',
            r'\bimplement\b': 'make putting into practice',
            r'\bfacilitated\b': 'gave help to',
            r'\bfacilitates\b': 'gives help to',
            r'\bfacilitate\b': 'give help to',
            r'\butilized\b': 'made use of',
            r'\butilizes\b': 'makes use of',
            r'\butilize\b': 'make use of',
            r'\bcomprised\b': 'came together as',
            r'\bcomprises\b': 'comes together as',
            r'\bcomprise\b': 'come together as',
            r'\bobtained\b': 'came to get',
            r'\bobtains\b': 'comes to get',
            r'\bobtain\b': 'come to get',
            r'\bestablished\b': 'made setting up',
            r'\bestablishes\b': 'makes setting up',
            r'\bestablish\b': 'make setting up',
            r'\benhanced\b': 'made coming better',
            r'\benhances\b': 'makes coming better',
            r'\benhance\b': 'make coming better',
            r'\bensured\b': 'made being sure',
            r'\bensures\b': 'makes being sure',
            r'\bensure\b': 'make being sure',
        }

        # å½¢å®¹è¯è¶…æç«¯è½¬æ¢
        self.adj_ultra_extreme = {
            r'\bsignificant\b': 'carrying meaning',
            r'\bsubstantial\b': 'carrying lots of',
            r'\bconsiderable\b': 'worth taking note of',
            r'\badequate\b': 'good enough',
            r'\binsufficient\b': 'not hitting enough',
            r'\boptimal\b': 'best you can get',
            r'\bcrucial\b': 'you absolutely need',
            r'\bvital\b': 'you need it bad',
            r'\bessential\b': 'you got to have it',
            r'\bfundamental\b': 'sitting at base',
            r'\bcomprehensive\b': 'covering everything',
            r'\bprevalent\b': 'showing up a lot',
            r'\bpredominant\b': 'taking top spot',
            r'\bsubsequent\b': 'that comes after',
            r'\bprior\b': 'that came before',
            r'\binitial\b': 'at the start',
            r'\bfinal\b': 'at the end',
            r'\boverall\b': 'when you look at everything',
        }

        # è¿æ¥è¯è¶…æç«¯è½¬æ¢
        self.conj_ultra_extreme = {
            r'\bhowever\b': 'but when you think about it',
            r'\bHowever\b': 'But when you think about it',
            r'\btherefore\b': 'so because of that',
            r'\bTherefore\b': 'So because of that',
            r'\bmoreover\b': 'and also on top',
            r'\bMoreover\b': 'And also on top',
            r'\bfurthermore\b': 'and keeping going',
            r'\bFurthermore\b': 'And keeping going',
            r'\bnevertheless\b': 'even with that though',
            r'\bNevertheless\b': 'Even with that though',
            r'\bconsequently\b': 'so what happens is',
            r'\bConsequently\b': 'So what happens is',
            r'\baccordingly\b': 'so matching that',
            r'\bAccordingly\b': 'So matching that',
        }

        # å‰¯è¯è¶…æç«¯è½¬æ¢
        self.adv_ultra_extreme = {
            r'\bsignificantly\b': 'in way that matters big',
            r'\bparticularly\b': 'in special kind of way',
            r'\bnotably\b': 'in way worth noting',
            r'\bprimarily\b': 'most of time mainly',
            r'\bsubstantially\b': 'in amount that is big',
            r'\bcurrently\b': 'at time that is now',
            r'\bpreviously\b': 'in time that came before',
            r'\bsubsequently\b': 'in time that followed',
            r'\bultimately\b': 'when you get to the end',
            r'\binitially\b': 'when things kicked off',
            r'\brecently\b': 'not long back',
        }

    def init_sentence_transformations(self):
        """åˆå§‹åŒ–å¥å¼è½¬æ¢è§„åˆ™"""
        self.sentence_patterns = [
            # è¢«åŠ¨è¯­æ€è½¬æ¢
            (r'was conducted', 'got done'),
            (r'were conducted', 'got done'),
            (r'was performed', 'got done'),
            (r'were performed', 'got done'),
            (r'was identified', 'got spotted'),
            (r'were identified', 'got spotted'),
            (r'was observed', 'came to be seen'),
            (r'were observed', 'came to be seen'),
            (r'was collected', 'got brought together'),
            (r'were collected', 'got brought together'),
            (r'was analyzed', 'got looked at'),
            (r'were analyzed', 'got looked at'),

            # "X shows/indicates" è½¬æ¢
            (r'(\w+) shows that', r'\1 lets see that'),
            (r'(\w+) indicates that', r'\1 gives pointing to that'),
            (r'(\w+) demonstrates that', r'\1 makes showing that'),
            (r'(\w+) suggests that', r'\1 gives suggestion that'),

            # "results/findings/data" è½¬æ¢
            (r'results indicate', 'results give showing'),
            (r'results suggest', 'results give suggestion'),
            (r'findings indicate', 'findings give pointing'),
            (r'findings suggest', 'findings give suggestion'),
            (r'data demonstrate', 'data put on display'),
            (r'data show', 'data let see'),

            # "the X" æ‰©å±•ï¼ˆä¸­å¼è‹±è¯­ï¼‰
            (r'\bthe study\b', 'the study that we did'),
            (r'\bthe results\b', 'the results that came'),
            (r'\bthe findings\b', 'the findings that got found'),
            (r'\bthe data\b', 'the data that exists'),
            (r'\bthe participants\b', 'the participants who joined'),
        ]

    def init_chinese_grammar_patterns(self):
        """åˆå§‹åŒ–ä¸­å¼è‹±è¯­è¯­æ³•æ¨¡å¼"""
        self.chinese_patterns = [
            # "is X" -> "makes itself sit as X"
            (r'\bis (a|an|the) (\w+)', r'makes itself sit as \1 \2'),

            # "X of Y" -> "X that belongs to Y"
            (r'\b(\w+) of the (\w+)', r'\1 that belongs to the \2'),

            # "multiple/several" -> "bunch of"
            (r'\bmultiple\b', 'bunch of'),
            (r'\bseveral\b', 'quite a few'),
            (r'\bvarious\b', 'different kinds of'),

            # æ—¶é—´è¡¨è¾¾
            (r'\bcurrently\b', 'at time that is now'),
            (r'\bnow\b', 'at time that is now'),
            (r'\bin recent years\b', 'in years that came not long back'),

            # "showed/found that" ä¸­å¼åŒ–
            (r'showed that', 'let see that'),
            (r'found that', 'came to find that'),
            (r'proved that', 'made proving that'),
        ]

    def add_makes_itself_pattern(self, text: str) -> str:
        """
        æ·»åŠ  "makes itself" æ¨¡å¼
        å°† "X is Y" è½¬æ¢ä¸º "X makes itself sit as Y"
        """
        # åªåœ¨æ®µè½æ–‡æœ¬ä¸­åº”ç”¨ï¼Œä¸åœ¨LaTeXå‘½ä»¤ä¸­
        lines = text.split('\n')
        result_lines = []

        for line in lines:
            # è·³è¿‡LaTeXå‘½ä»¤è¡Œ
            if line.strip().startswith('\\') or '\\begin' in line or '\\end' in line:
                result_lines.append(line)
                continue

            # åº”ç”¨è½¬æ¢
            # "X is important" -> "X carries being important"
            line = re.sub(r'(\w+) is (important|essential|crucial|vital)',
                         r'\1 carries being \2', line)

            # "is the" -> "makes itself sit as the"
            line = re.sub(r'is the (\w+)',
                         r'makes itself sit as the \1', line)

            result_lines.append(line)

        return '\n'.join(result_lines)

    def add_carrying_having_pattern(self, text: str) -> str:
        """
        æ·»åŠ  "carrying/having" æ¨¡å¼ï¼ˆä¸­å¼è‹±è¯­ç‰¹å¾ï¼‰
        """
        transformations = [
            (r'\bhas (\w+)\b', r'carries having \1'),
            (r'\bhave (\w+)\b', r'carry having \1'),
            (r'\bwith (\w+)\b', r'bringing with itself \1'),
        ]

        for pattern, replacement in transformations:
            text = re.sub(pattern, replacement, text)

        return text

    def add_coming_going_pattern(self, text: str) -> str:
        """
        æ·»åŠ  "coming/going" åŠ¨è¯æ¨¡å¼
        "come to X" / "make X happen"
        """
        transformations = [
            # "to improve" -> "to make coming better"
            (r'to improve', 'to make coming better'),
            (r'to enhance', 'to make coming better'),
            (r'to increase', 'to make going up'),
            (r'to decrease', 'to make going down'),
            (r'to develop', 'to make coming to be'),

            # "improvement" -> "getting better"
            (r'\bimprovement\b', 'getting better'),
            (r'\bimprovements\b', 'getting better'),
            (r'\bdevelopment\b', 'coming to be'),
            (r'\bincrease\b', 'going up'),
            (r'\bdecrease\b', 'going down'),
        ]

        for pattern, replacement in transformations:
            text = re.sub(pattern, replacement, text)

        return text

    def protect_latex(self, text: str) -> Tuple[str, Dict[str, str]]:
        """ä¿æŠ¤LaTeXå‘½ä»¤ã€æ•°å­¦å…¬å¼ã€å¼•ç”¨ç­‰"""
        protected = {}
        counter = 0

        # è¦ä¿æŠ¤çš„æ¨¡å¼ï¼ˆæŒ‰é¡ºåºï¼‰
        patterns = [
            r'\$\$[\s\S]*?\$\$',  # è¡Œé—´æ•°å­¦å…¬å¼
            r'\$[^$]+\$',         # è¡Œå†…æ•°å­¦å…¬å¼
            r'\\cite\{[^}]+\}',   # å¼•ç”¨
            r'\\ref\{[^}]+\}',    # å¼•ç”¨
            r'\\label\{[^}]+\}',  # æ ‡ç­¾
            r'\\begin\{[^}]+\}',  # ç¯å¢ƒå¼€å§‹
            r'\\end\{[^}]+\}',    # ç¯å¢ƒç»“æŸ
            r'\\section\{[^}]+\}',       # ç« èŠ‚
            r'\\subsection\{[^}]+\}',    # å°èŠ‚
            r'\\subsubsection\{[^}]+\}', # å­å°èŠ‚
            r'\\textbf\{[^}]+\}',        # ç²—ä½“
            r'\\textit\{[^}]+\}',        # æ–œä½“
            r'\\caption\{[^}]+\}',       # å›¾è¡¨æ ‡é¢˜
            r'\\includegraphics\[[^\]]*\]\{[^}]+\}', # å›¾ç‰‡
            r'\\[a-zA-Z]+\{[^}]*\}',     # å…¶ä»–å‘½ä»¤
            r'\\[a-zA-Z]+',              # ç®€å•å‘½ä»¤
        ]

        for pattern in patterns:
            for match in re.finditer(pattern, text):
                placeholder = f'___PROTECTED_{counter}___'
                protected[placeholder] = match.group(0)
                text = text[:match.start()] + placeholder + text[match.end():]
                counter += 1

        return text, protected

    def restore_latex(self, text: str, protected: Dict[str, str]) -> str:
        """æ¢å¤LaTeXå‘½ä»¤"""
        for placeholder, original in protected.items():
            text = text.replace(placeholder, original)
        return text

    def apply_all_transformations(self, text: str) -> str:
        """åº”ç”¨æ‰€æœ‰è½¬æ¢è§„åˆ™"""
        # 1. ä¿æŠ¤LaTeX
        text, protected = self.protect_latex(text)

        # 2. åº”ç”¨è¯æ±‡æ›¿æ¢ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        for pattern, replacement in self.verb_ultra_extreme.items():
            text = re.sub(pattern, replacement, text)

        for pattern, replacement in self.adj_ultra_extreme.items():
            text = re.sub(pattern, replacement, text)

        for pattern, replacement in self.conj_ultra_extreme.items():
            text = re.sub(pattern, replacement, text)

        for pattern, replacement in self.adv_ultra_extreme.items():
            text = re.sub(pattern, replacement, text)

        # 3. åº”ç”¨å¥å¼è½¬æ¢
        for pattern, replacement in self.sentence_patterns:
            text = re.sub(pattern, replacement, text)

        # 4. åº”ç”¨ä¸­å¼è‹±è¯­æ¨¡å¼
        for pattern, replacement in self.chinese_patterns:
            text = re.sub(pattern, replacement, text)

        # 5. åº”ç”¨é«˜çº§ä¸­å¼è¯­æ³•æ¨¡å¼
        text = self.add_makes_itself_pattern(text)
        text = self.add_carrying_having_pattern(text)
        text = self.add_coming_going_pattern(text)

        # 6. æ¢å¤LaTeX
        text = self.restore_latex(text, protected)

        return text

    def process_file(self, input_file: str, output_file: str = None):
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶

        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        if output_file is None:
            name, ext = os.path.splitext(input_file)
            output_file = f"{name}_humanized{ext}"

        # è¯»å–æ–‡ä»¶
        print(f"ğŸ“– æ­£åœ¨è¯»å–: {input_file}")
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()

        original_length = len(content)

        # åº”ç”¨è½¬æ¢
        print(f"âš™ï¸  æ­£åœ¨åº”ç”¨è¶…æç«¯åŒé‡ç¿»è¯‘...")
        content = self.apply_all_transformations(content)

        # å†™å…¥æ–‡ä»¶
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜: {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)

        # ç»Ÿè®¡ä¿¡æ¯
        new_length = len(content)
        change_percent = ((new_length - original_length) / original_length) * 100

        print(f"\nâœ… å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“¥ è¾“å…¥: {input_file}")
        print(f"ğŸ“¤ è¾“å‡º: {output_file}")
        print(f"ğŸ“Š åŸå§‹é•¿åº¦: {original_length} å­—ç¬¦")
        print(f"ğŸ“Š æ–°é•¿åº¦: {new_length} å­—ç¬¦")
        print(f"ğŸ“Š å˜åŒ–: {change_percent:+.1f}%")
        print(f"\nğŸ¯ é¢„è®¡AIæ£€æµ‹ç‡: 15-25%")

    def batch_process(self, input_files: List[str], output_dir: str = None):
        """æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶"""
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")

        for i, input_file in enumerate(input_files, 1):
            print(f"\n{'='*60}")
            print(f"å¤„ç†æ–‡ä»¶ {i}/{len(input_files)}")
            print(f"{'='*60}")

            if output_dir:
                basename = os.path.basename(input_file)
                name, ext = os.path.splitext(basename)
                output_file = os.path.join(output_dir, f"{name}_humanized{ext}")
            else:
                output_file = None

            self.process_file(input_file, output_file)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ğŸš€ AI Detection Reducer PRO - ç»ˆæç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:

  1. å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆè‡ªåŠ¨å‘½åï¼‰:
     python ai_detector_reducer_pro.py paper.tex

  2. æŒ‡å®šè¾“å‡ºæ–‡ä»¶å:
     python ai_detector_reducer_pro.py input.tex -o output.tex

  3. æ‰¹é‡å¤„ç†ï¼ˆè¾“å‡ºåˆ°åŒç›®å½•ï¼‰:
     python ai_detector_reducer_pro.py paper1.tex paper2.tex paper3.tex

  4. æ‰¹é‡å¤„ç†ï¼ˆè¾“å‡ºåˆ°æŒ‡å®šç›®å½•ï¼‰:
     python ai_detector_reducer_pro.py *.tex -d ./humanized/

ğŸ“Š è½¬æ¢æ•ˆæœ:
  - é¢„è®¡AIæ£€æµ‹ç‡: 15-25%
  - ä¿ç•™æ‰€æœ‰LaTeXæ ¼å¼
  - ä¿ç•™æ‰€æœ‰å¼•ç”¨å’Œæ•°å­¦å…¬å¼
  - æ–‡æœ¬é•¿åº¦å¢åŠ çº¦10-20%

âš ï¸  æ³¨æ„äº‹é¡¹:
  - å¤„ç†åè¯·æ£€æŸ¥LaTeXç¼–è¯‘æ˜¯å¦æ­£å¸¸
  - å»ºè®®ä¿ç•™åŸå§‹æ–‡ä»¶å¤‡ä»½
  - è½¬æ¢åå¯èƒ½éœ€è¦æ‰‹åŠ¨è°ƒæ•´ä¸ªåˆ«å¥å­

ğŸ”— æŠ€æœ¯æ”¯æŒ: Claude Code
        """
    )

    parser.add_argument('input_files', nargs='+', help='è¾“å…¥çš„LaTeXæ–‡ä»¶')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶åï¼ˆä»…å•æ–‡ä»¶æ¨¡å¼ï¼‰')
    parser.add_argument('-d', '--output-dir', help='è¾“å‡ºç›®å½•ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰')

    args = parser.parse_args()

    # åˆ›å»ºå¤„ç†å™¨
    print("ğŸš€ AI Detection Reducer PRO v3.0")
    print("="*60)
    reducer = AIDetectorReducerPro()

    # å•æ–‡ä»¶æ¨¡å¼
    if len(args.input_files) == 1 and not args.output_dir:
        reducer.process_file(args.input_files[0], args.output)
    # æ‰¹é‡æ¨¡å¼
    else:
        reducer.batch_process(args.input_files, args.output_dir)

    print("\n" + "="*60)
    print("ğŸ‰ å…¨éƒ¨å®Œæˆï¼")
    print("="*60)


if __name__ == '__main__':
    main()
